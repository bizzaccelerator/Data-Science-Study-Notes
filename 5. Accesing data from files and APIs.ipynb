{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading, Storage, and File Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing data and getting it into your script is the first step of any data project. Here it is covered several ways of importing data from files and other sources into a python application, as weel as ways to export data to files. \n",
    "\n",
    "Input and Output typically falls into a few main categories: rerading text files and other more efficient on-disk format, loading data from databases, and interacting with network sources like web APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "- 1. Reading and writing data in text formats.\n",
    "    - Handling Plain text.\n",
    "    - Getting Tabular data from a text file.\n",
    "    - Reading text files in pieces.\n",
    "    - Writing data to text format.\n",
    "    - Operations on other data formats.\n",
    "- 2. Interacting with network sources like web APIs.\n",
    "- 3. Loading data from databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reading and writing data in text formats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Plain text \n",
    "\n",
    "Text can arrive in different formats. Sometimes plain text `(.txt)` is of interest. Text files are perhaps the most common file type you'll encounter. Luckily, Python doesn't require a special library for processing it; you can simply rely on the methods of the file object returned by the `*open( )*` function. \n",
    "\n",
    "To Python, a text file is a sequence of string objects, each of those is one line of text file - that is, a sequence of character ending in a nondisplayed new line character `(\\n)` or hard return. \n",
    "\n",
    "Please take a look to the following example. To humans, the passage consist of four paragraphs that includes several sentences; however, to Python, the passage includes four nonempty lines and three blank lines between them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Marine Mammal Center (TMMC) is a private, non-profit U.S. organization that was established in 1975 for the purpose of rescuing, rehabilitating and releasing marine mammals who are injured, ill or abandoned. It was founded in Sausalito, California, by Lloyd Smalley, Pat Arrigoni and Paul Maxwell. Since 1975, TMMC has rescued over 24,000 marine mammals. \n",
      "\n",
      "It also serves as a center for environmental research and education regarding marine mammals, namely cetaceans (whales, dolphins and porpoises), pinnipeds (seals, fur seals, walruses and sea lions), otters and sirenians (manatees and dugongs). \n",
      "\n",
      "Marine mammal abandonment refers to maternal separation; pups that have been separated from their mother before weaning. At the center, they receive specialized veterinary care: they are diagnosed, treated, rehabilitated and ideally, released back into the wild. \n",
      "\n",
      "Animals in need of assistance are usually identified by a member of the public who has contacted the center. These animals represent the following major species: California sea lions, northern elephant seals, Pacific harbor seals, northern fur seals, Guadalupe fur seals, Hawaiian monk seals, and southern sea otters. On a few occasions, TMMC has taken in Steller sea lions and bottlenose/Pacific white-sided dolphins. The only non-mammals that TMMC takes in are sea turtles.\n"
     ]
    }
   ],
   "source": [
    "# Reading a text file in Python \n",
    "\n",
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\Marine.txt\"\n",
    "\n",
    "with open(path, 'r') as f:  # The first artgument 'path' specify where the file is located, the second controls how the file will be used, 'r' for read only.\n",
    "    content = f.read()      # The read method reads the entire content of the file object.\n",
    "print(content)\n",
    "\n",
    "# the with keyword is used to ensure that the file object is properly closed when the action is performed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than print the lines, you can send them to a list using a list comprenhension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Marine Mammal Center (TMMC) is a private, non-profit U.S. organization that was established in 1975 for the purpose of rescuing, rehabilitating and releasing marine mammals who are injured, ill or abandoned. It was founded in Sausalito, California, by Lloyd Smalley, Pat Arrigoni and Paul Maxwell. Since 1975, TMMC has rescued over 24,000 marine mammals.',\n",
       " 'It also serves as a center for environmental research and education regarding marine mammals, namely cetaceans (whales, dolphins and porpoises), pinnipeds (seals, fur seals, walruses and sea lions), otters and sirenians (manatees and dugongs).',\n",
       " 'Marine mammal abandonment refers to maternal separation; pups that have been separated from their mother before weaning. At the center, they receive specialized veterinary care: they are diagnosed, treated, rehabilitated and ideally, released back into the wild.',\n",
       " 'Animals in need of assistance are usually identified by a member of the public who has contacted the center. These animals represent the following major species: California sea lions, northern elephant seals, Pacific harbor seals, northern fur seals, Guadalupe fur seals, Hawaiian monk seals, and southern sea otters. On a few occasions, TMMC has taken in Steller sea lions and bottlenose/Pacific white-sided dolphins. The only non-mammals that TMMC takes in are sea turtles.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a list from a text file in Python \n",
    "\n",
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\Marine.txt\"\n",
    "\n",
    "with open(path, 'r') as f:  \n",
    "    lst = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point onwards, you can use any method available for processing strings in Python, so you can organize it a tabular form. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Tabular data from a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular data is easy to manage with `pandas`. Pandas features a number of functions for reading tabular data as a DataFrame object. Most of the parsing functions in pandas use a character as a delimiter between  columns. However, in some cases, a table might not have a fixed delimiter, using whitespace or some other pattern to separate fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MemStartDate</th>\n",
       "      <th>TotalPrice</th>\n",
       "      <th>UnitPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-07-13</td>\n",
       "      <td>50.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-13</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-08-13</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  MemStartDate  TotalPrice  UnitPrice\n",
       "0   2007-07-13        50.5        5.5\n",
       "1   2006-01-13        10.4        1.4\n",
       "2   2010-08-13         3.5        0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of how to use a space as delimiter between columns. \n",
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\Price_table.txt\"\n",
    "table = pd.read_table(path, sep='\\s+') # The term (\\s+) is a regular expression used to indicates the elements after a space.\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As show in previous chapters, the most used parsing fucntion to get data from a text file is the `read_csv` function from pandas. This function loads data from a file, URL, or file-like object using comma as default delimiter. That's why these files are simply called *comma separated value (CSV)* files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 19:01:00</td>\n",
       "      <td>2013-06-28 19:17:00</td>\n",
       "      <td>993</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 22:53:00</td>\n",
       "      <td>2013-06-28 23:03:00</td>\n",
       "      <td>623</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-30 14:43:00</td>\n",
       "      <td>2013-06-30 15:01:00</td>\n",
       "      <td>1040</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Dearborn St &amp; Monroe St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender            starttime             stoptime  tripduration  \\\n",
       "0   Male  2013-06-28 19:01:00  2013-06-28 19:17:00           993   \n",
       "1   Male  2013-06-28 22:53:00  2013-06-28 23:03:00           623   \n",
       "2   Male  2013-06-30 14:43:00  2013-06-30 15:01:00          1040   \n",
       "\n",
       "              from_station_name  start_capacity          to_station_name  \\\n",
       "0     Lake Shore Dr & Monroe St            11.0    Michigan Ave & Oak St   \n",
       "1  Clinton St & Washington Blvd            31.0     Wells St & Walton St   \n",
       "2  Sheffield Ave & Kingsbury St            15.0  Dearborn St & Monroe St   \n",
       "\n",
       "   end_capacity  temperature  wind_speed        events  \n",
       "0          15.0         73.9        12.7  mostlycloudy  \n",
       "1          19.0         69.1         6.9  partlycloudy  \n",
       "2          23.0         73.0        16.1  mostlycloudy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data from a local CSV file\n",
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\bikes.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*read_csv* and many other data reading functions perform _type inference_, because the column data types are not part of the data format. It is always recommended to check data types in our data frame using `info()`. In our example, *starttime* and *stoptime* columns were identified as text (object); however a correct type would be the date-time type. This transformation is easily done as explained in chapter 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50089 entries, 0 to 50088\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             50089 non-null  object \n",
      " 1   starttime          50089 non-null  object \n",
      " 2   stoptime           50089 non-null  object \n",
      " 3   tripduration       50089 non-null  int64  \n",
      " 4   from_station_name  50089 non-null  object \n",
      " 5   start_capacity     50083 non-null  float64\n",
      " 6   to_station_name    50089 non-null  object \n",
      " 7   end_capacity       50077 non-null  float64\n",
      " 8   temperature        50089 non-null  float64\n",
      " 9   wind_speed         50089 non-null  float64\n",
      " 10  events             50089 non-null  object \n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the infered data type in each column\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file will not always have a header row. Pandas will assign default column names to each column. These default names will be integers starting from 0 up to the number of columns in the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>49.00</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>994.000</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>9.951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>58.00</td>\n",
       "      <td>47</td>\n",
       "      <td>186</td>\n",
       "      <td>9.956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>58.00</td>\n",
       "      <td>47</td>\n",
       "      <td>186</td>\n",
       "      <td>9.956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>9.951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>30</td>\n",
       "      <td>136</td>\n",
       "      <td>9.949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>49.00</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>994.000</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>44.00</td>\n",
       "      <td>28</td>\n",
       "      <td>129</td>\n",
       "      <td>9.938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3      4   5    6        7     8     9     10  11\n",
       "0  7.0  0.27  0.36  20.7  45.00  45  170    1.001  3.00  0.45   8.8   6\n",
       "1  6.3  0.30  0.34   1.6  49.00  14  132  994.000  3.30  0.49   9.5   6\n",
       "2  8.1  0.28  0.40   6.9   0.05  30   97    9.951  3.26  0.44  10.1   6\n",
       "3  7.2  0.23  0.32   8.5  58.00  47  186    9.956  3.19  0.40   9.9   6\n",
       "4  7.2  0.23  0.32   8.5  58.00  47  186    9.956  3.19  0.40   9.9   6\n",
       "5  8.1  0.28  0.40   6.9   0.05  30   97    9.951  3.26  0.44  10.1   6\n",
       "6  6.2  0.32  0.16   7.0  45.00  30  136    9.949  3.18  0.47   9.6   6\n",
       "7  7.0  0.27  0.36  20.7  45.00  45  170    1.001  3.00  0.45   8.8   6\n",
       "8  6.3  0.30  0.34   1.6  49.00  14  132  994.000  3.30  0.49   9.5   6\n",
       "9  8.1  0.22  0.43   1.5  44.00  28  129    9.938  3.22  0.45  11.0   6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a file without column names\n",
    "data2 = pd.read_csv(r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\data-wine-white.csv\", header=None)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know exactly what data we are analyzing. To specify the column names, we can set them from the load operation as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>49.00</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>994.000</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>9.951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>58.00</td>\n",
       "      <td>47</td>\n",
       "      <td>186</td>\n",
       "      <td>9.956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>58.00</td>\n",
       "      <td>47</td>\n",
       "      <td>186</td>\n",
       "      <td>9.956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>30</td>\n",
       "      <td>97</td>\n",
       "      <td>9.951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>30</td>\n",
       "      <td>136</td>\n",
       "      <td>9.949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>45.00</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>1.001</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>49.00</td>\n",
       "      <td>14</td>\n",
       "      <td>132</td>\n",
       "      <td>994.000</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.5</td>\n",
       "      <td>44.00</td>\n",
       "      <td>28</td>\n",
       "      <td>129</td>\n",
       "      <td>9.938</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      45.00   \n",
       "1            6.3              0.30         0.34             1.6      49.00   \n",
       "2            8.1              0.28         0.40             6.9       0.05   \n",
       "3            7.2              0.23         0.32             8.5      58.00   \n",
       "4            7.2              0.23         0.32             8.5      58.00   \n",
       "5            8.1              0.28         0.40             6.9       0.05   \n",
       "6            6.2              0.32         0.16             7.0      45.00   \n",
       "7            7.0              0.27         0.36            20.7      45.00   \n",
       "8            6.3              0.30         0.34             1.6      49.00   \n",
       "9            8.1              0.22         0.43             1.5      44.00   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                   45                   170    1.001  3.00       0.45   \n",
       "1                   14                   132  994.000  3.30       0.49   \n",
       "2                   30                    97    9.951  3.26       0.44   \n",
       "3                   47                   186    9.956  3.19       0.40   \n",
       "4                   47                   186    9.956  3.19       0.40   \n",
       "5                   30                    97    9.951  3.26       0.44   \n",
       "6                   30                   136    9.949  3.18       0.47   \n",
       "7                   45                   170    1.001  3.00       0.45   \n",
       "8                   14                   132  994.000  3.30       0.49   \n",
       "9                   28                   129    9.938  3.22       0.45   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  \n",
       "5     10.1        6  \n",
       "6      9.6        6  \n",
       "7      8.8        6  \n",
       "8      9.5        6  \n",
       "9     11.0        6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a file without column names. Names indicated by the analyst.\n",
    "column_names = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "data3 = pd.read_csv(r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\data-wine-white.csv\", names=column_names)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading text files in pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When processing very large files or figuring out the right set of arguments to correctly processing a file, you may only want to read in a small piece of a file or iterate through smaller chuncks of the file. \n",
    "\n",
    "If you want to only read a small number of rows (avoiding reading the entire file), we use the parameter `nrows`. This is usefull to get a taste of whats inside beffore commiting a big portion of resources to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>tripduration</th>\n",
       "      <th>from_station_name</th>\n",
       "      <th>start_capacity</th>\n",
       "      <th>to_station_name</th>\n",
       "      <th>end_capacity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>events</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 19:01:00</td>\n",
       "      <td>2013-06-28 19:17:00</td>\n",
       "      <td>993</td>\n",
       "      <td>Lake Shore Dr &amp; Monroe St</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Michigan Ave &amp; Oak St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-28 22:53:00</td>\n",
       "      <td>2013-06-28 23:03:00</td>\n",
       "      <td>623</td>\n",
       "      <td>Clinton St &amp; Washington Blvd</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Wells St &amp; Walton St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>69.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-06-30 14:43:00</td>\n",
       "      <td>2013-06-30 15:01:00</td>\n",
       "      <td>1040</td>\n",
       "      <td>Sheffield Ave &amp; Kingsbury St</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Dearborn St &amp; Monroe St</td>\n",
       "      <td>23.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-07-01 10:05:00</td>\n",
       "      <td>2013-07-01 10:16:00</td>\n",
       "      <td>667</td>\n",
       "      <td>Carpenter St &amp; Huron St</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Clark St &amp; Randolph St</td>\n",
       "      <td>31.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>mostlycloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>2013-07-01 11:16:00</td>\n",
       "      <td>2013-07-01 11:18:00</td>\n",
       "      <td>130</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>19.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>partlycloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender            starttime             stoptime  tripduration  \\\n",
       "0   Male  2013-06-28 19:01:00  2013-06-28 19:17:00           993   \n",
       "1   Male  2013-06-28 22:53:00  2013-06-28 23:03:00           623   \n",
       "2   Male  2013-06-30 14:43:00  2013-06-30 15:01:00          1040   \n",
       "3   Male  2013-07-01 10:05:00  2013-07-01 10:16:00           667   \n",
       "4   Male  2013-07-01 11:16:00  2013-07-01 11:18:00           130   \n",
       "\n",
       "              from_station_name  start_capacity          to_station_name  \\\n",
       "0     Lake Shore Dr & Monroe St            11.0    Michigan Ave & Oak St   \n",
       "1  Clinton St & Washington Blvd            31.0     Wells St & Walton St   \n",
       "2  Sheffield Ave & Kingsbury St            15.0  Dearborn St & Monroe St   \n",
       "3       Carpenter St & Huron St            19.0   Clark St & Randolph St   \n",
       "4        Damen Ave & Pierce Ave            19.0   Damen Ave & Pierce Ave   \n",
       "\n",
       "   end_capacity  temperature  wind_speed        events  \n",
       "0          15.0         73.9        12.7  mostlycloudy  \n",
       "1          19.0         69.1         6.9  partlycloudy  \n",
       "2          23.0         73.0        16.1  mostlycloudy  \n",
       "3          31.0         72.0        16.1  mostlycloudy  \n",
       "4          19.0         73.0        17.3  partlycloudy  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading only a piece of a file\n",
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\bikes.csv\"\n",
    "pd.read_csv(path,nrows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you want to read a file in pieces, specify a `chuncksize` as a numebr of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.io.parsers.readers.TextFileReader at 0x242712132b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\bikes.csv\"\n",
    "chunker = pd.read_csv(path, chunksize=1000)\n",
    "chunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TextParser object returned by the read_csv() function allowsyou to iterate over the parts of the file according to the chucksize. For example, we can iterate over the `bikes.csv` file, aggregating the value counts in the *gender* column like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Up to the iteration 1, we have:\n",
      " Male      764.0\n",
      "Female    236.0\n",
      "dtype: float64\n",
      "Up to the iteration 2, we have:\n",
      " Male      1560.0\n",
      "Female     440.0\n",
      "dtype: float64\n",
      "Up to the iteration 3, we have:\n",
      " Male      2377.0\n",
      "Female     623.0\n",
      "dtype: float64\n",
      "Up to the iteration 4, we have:\n",
      " Male      3157.0\n",
      "Female     843.0\n",
      "dtype: float64\n",
      "Up to the iteration 5, we have:\n",
      " Male      3884.0\n",
      "Female    1116.0\n",
      "dtype: float64\n",
      "Up to the iteration 6, we have:\n",
      " Male      4604.0\n",
      "Female    1396.0\n",
      "dtype: float64\n",
      "Up to the iteration 7, we have:\n",
      " Male      5347.0\n",
      "Female    1653.0\n",
      "dtype: float64\n",
      "Up to the iteration 8, we have:\n",
      " Male      6079.0\n",
      "Female    1921.0\n",
      "dtype: float64\n",
      "Up to the iteration 9, we have:\n",
      " Male      6827.0\n",
      "Female    2173.0\n",
      "dtype: float64\n",
      "Up to the iteration 10, we have:\n",
      " Male      7602.0\n",
      "Female    2398.0\n",
      "dtype: float64\n",
      "Up to the iteration 11, we have:\n",
      " Male      8409.0\n",
      "Female    2591.0\n",
      "dtype: float64\n",
      "Up to the iteration 12, we have:\n",
      " Male      9191.0\n",
      "Female    2809.0\n",
      "dtype: float64\n",
      "Up to the iteration 13, we have:\n",
      " Male      9939.0\n",
      "Female    3061.0\n",
      "dtype: float64\n",
      "Up to the iteration 14, we have:\n",
      " Male      10659.0\n",
      "Female     3341.0\n",
      "dtype: float64\n",
      "Up to the iteration 15, we have:\n",
      " Male      11378.0\n",
      "Female     3622.0\n",
      "dtype: float64\n",
      "Up to the iteration 16, we have:\n",
      " Male      12107.0\n",
      "Female     3893.0\n",
      "dtype: float64\n",
      "Up to the iteration 17, we have:\n",
      " Male      12826.0\n",
      "Female     4174.0\n",
      "dtype: float64\n",
      "Up to the iteration 18, we have:\n",
      " Male      13560.0\n",
      "Female     4440.0\n",
      "dtype: float64\n",
      "Up to the iteration 19, we have:\n",
      " Male      14297.0\n",
      "Female     4703.0\n",
      "dtype: float64\n",
      "Up to the iteration 20, we have:\n",
      " Male      15071.0\n",
      "Female     4929.0\n",
      "dtype: float64\n",
      "Up to the iteration 21, we have:\n",
      " Male      15860.0\n",
      "Female     5140.0\n",
      "dtype: float64\n",
      "Up to the iteration 22, we have:\n",
      " Male      16678.0\n",
      "Female     5322.0\n",
      "dtype: float64\n",
      "Up to the iteration 23, we have:\n",
      " Male      17478.0\n",
      "Female     5522.0\n",
      "dtype: float64\n",
      "Up to the iteration 24, we have:\n",
      " Male      18245.0\n",
      "Female     5755.0\n",
      "dtype: float64\n",
      "Up to the iteration 25, we have:\n",
      " Male      18996.0\n",
      "Female     6004.0\n",
      "dtype: float64\n",
      "Up to the iteration 26, we have:\n",
      " Male      19734.0\n",
      "Female     6266.0\n",
      "dtype: float64\n",
      "Up to the iteration 27, we have:\n",
      " Male      20466.0\n",
      "Female     6534.0\n",
      "dtype: float64\n",
      "Up to the iteration 28, we have:\n",
      " Male      21183.0\n",
      "Female     6817.0\n",
      "dtype: float64\n",
      "Up to the iteration 29, we have:\n",
      " Male      21872.0\n",
      "Female     7128.0\n",
      "dtype: float64\n",
      "Up to the iteration 30, we have:\n",
      " Male      22582.0\n",
      "Female     7418.0\n",
      "dtype: float64\n",
      "Up to the iteration 31, we have:\n",
      " Male      23316.0\n",
      "Female     7684.0\n",
      "dtype: float64\n",
      "Up to the iteration 32, we have:\n",
      " Male      24058.0\n",
      "Female     7942.0\n",
      "dtype: float64\n",
      "Up to the iteration 33, we have:\n",
      " Male      24811.0\n",
      "Female     8189.0\n",
      "dtype: float64\n",
      "Up to the iteration 34, we have:\n",
      " Male      25557.0\n",
      "Female     8443.0\n",
      "dtype: float64\n",
      "Up to the iteration 35, we have:\n",
      " Male      26333.0\n",
      "Female     8667.0\n",
      "dtype: float64\n",
      "Up to the iteration 36, we have:\n",
      " Male      27130.0\n",
      "Female     8870.0\n",
      "dtype: float64\n",
      "Up to the iteration 37, we have:\n",
      " Male      27889.0\n",
      "Female     9111.0\n",
      "dtype: float64\n",
      "Up to the iteration 38, we have:\n",
      " Male      28652.0\n",
      "Female     9348.0\n",
      "dtype: float64\n",
      "Up to the iteration 39, we have:\n",
      " Male      29378.0\n",
      "Female     9622.0\n",
      "dtype: float64\n",
      "Up to the iteration 40, we have:\n",
      " Male      30112.0\n",
      "Female     9888.0\n",
      "dtype: float64\n",
      "Up to the iteration 41, we have:\n",
      " Male      30858.0\n",
      "Female    10142.0\n",
      "dtype: float64\n",
      "Up to the iteration 42, we have:\n",
      " Male      31597.0\n",
      "Female    10403.0\n",
      "dtype: float64\n",
      "Up to the iteration 43, we have:\n",
      " Male      32326.0\n",
      "Female    10674.0\n",
      "dtype: float64\n",
      "Up to the iteration 44, we have:\n",
      " Male      33034.0\n",
      "Female    10966.0\n",
      "dtype: float64\n",
      "Up to the iteration 45, we have:\n",
      " Male      33779.0\n",
      "Female    11221.0\n",
      "dtype: float64\n",
      "Up to the iteration 46, we have:\n",
      " Male      34522.0\n",
      "Female    11478.0\n",
      "dtype: float64\n",
      "Up to the iteration 47, we have:\n",
      " Male      35274.0\n",
      "Female    11726.0\n",
      "dtype: float64\n",
      "Up to the iteration 48, we have:\n",
      " Male      36029.0\n",
      "Female    11971.0\n",
      "dtype: float64\n",
      "Up to the iteration 49, we have:\n",
      " Male      36797.0\n",
      "Female    12203.0\n",
      "dtype: float64\n",
      "Up to the iteration 50, we have:\n",
      " Male      37580.0\n",
      "Female    12420.0\n",
      "dtype: float64\n",
      "Up to the iteration 51, we have:\n",
      " Male      37654.0\n",
      "Female    12435.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\bikes.csv\"\n",
    "chunker = pd.read_csv(path, chunksize=1000)\n",
    "\n",
    "tot = pd.Series([], dtype=\"float64\")    # Artificial varible used to count men and women in the dataset\n",
    "data_complete = pd.DataFrame()          # New DataFrame to be filled with every chunk\n",
    "i = 0                                   # Counter of the interation\n",
    "\n",
    "for piece in chunker:\n",
    "    i = i + 1\n",
    "    tot = tot.add(piece['gender'].value_counts(), fill_value=0) # Calculates the accumulated number of men and women after every iteration\n",
    "    print(f'Up to the iteration {i}, we have:\\n',tot)           # Print the result at every stage\n",
    "    data_complete = pd.concat([piece,data_complete])            # Aggregates the target DataFrame\n",
    "\n",
    "tot = tot.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final compilation of the TextParser object is the desired DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 50089 entries, 50000 to 999\n",
      "Data columns (total 11 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   gender             50089 non-null  object \n",
      " 1   starttime          50089 non-null  object \n",
      " 2   stoptime           50089 non-null  object \n",
      " 3   tripduration       50089 non-null  int64  \n",
      " 4   from_station_name  50089 non-null  object \n",
      " 5   start_capacity     50083 non-null  float64\n",
      " 6   to_station_name    50089 non-null  object \n",
      " 7   end_capacity       50077 non-null  float64\n",
      " 8   temperature        50089 non-null  float64\n",
      " 9   wind_speed         50089 non-null  float64\n",
      " 10  events             50089 non-null  object \n",
      "dtypes: float64(4), int64(1), object(6)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_complete.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing data to text format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data can also be exported to a delimited format. Let's consider one of the DataFrames read before, `data3`. We can write the data in our DataFrame out to a comma separated value(csv) file by using the method `.to_csv()` in pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of exporting a DataFrame into a csv file\n",
    "\n",
    "destination_path=r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\wine-white-with-headers.csv\"\n",
    "\n",
    "data3.to_csv(destination_path) #Please note that the destination path includes the name of the new exported file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform tailored exporting from the data by subsetting the columns and rows, and in order of your choosing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of exporting selected columns from a DataFrame into a csv file\n",
    "\n",
    "destination_path=r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\wine-white-reduced.csv\"\n",
    "\n",
    "data3.to_csv(destination_path, index=False, columns=['volatile acidity', 'chlorides', 'pH', 'quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations on other data formats \n",
    "\n",
    "One of the easiest way to store data (also knonw as serialization) efficiently in binary format is using Python's built-in `pickle` serialization. Pickle is left out of this chapter because it is only recommended as short-term storage format, and its use in dicline. \n",
    "\n",
    "`Apache Parquet` is a format nowadays used to store data on remote servers, like Amazon S3 or HDFS. It was designed for distribuited storage, but it is ease to read in using the pandas' function `read_parquet()`. Otherwise it is similar to other text formats explained.\n",
    "\n",
    "Logistics to load and/or write data from(to) many other text data formats (such as excel) are pretty similar. Thus, study of the official Python documentation is suggested to the reader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 00:59:47</td>\n",
       "      <td>2019-01-01 01:18:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-12-21 13:48:30</td>\n",
       "      <td>2018-12-21 13:52:40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:52:25</td>\n",
       "      <td>2018-11-28 15:55:45</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-28 15:56:57</td>\n",
       "      <td>2018-11-28 15:58:33</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>55.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2019-01-01 00:46:40   2019-01-01 00:53:20              1.0   \n",
       "1         1  2019-01-01 00:59:47   2019-01-01 01:18:59              1.0   \n",
       "2         2  2018-12-21 13:48:30   2018-12-21 13:52:40              3.0   \n",
       "3         2  2018-11-28 15:52:25   2018-11-28 15:55:45              5.0   \n",
       "4         2  2018-11-28 15:56:57   2018-11-28 15:58:33              5.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.5         1.0                  N           151           239   \n",
       "1            2.6         1.0                  N           239           246   \n",
       "2            0.0         1.0                  N           236           236   \n",
       "3            0.0         1.0                  N           193           193   \n",
       "4            0.0         2.0                  N           193           193   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          7.0    0.5      0.5        1.65           0.0   \n",
       "1             1         14.0    0.5      0.5        1.00           0.0   \n",
       "2             1          4.5    0.5      0.5        0.00           0.0   \n",
       "3             2          3.5    0.5      0.5        0.00           0.0   \n",
       "4             2         52.0    0.0      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge airport_fee  \n",
       "0                    0.3          9.95                   NaN        None  \n",
       "1                    0.3         16.30                   NaN        None  \n",
       "2                    0.3          5.80                   NaN        None  \n",
       "3                    0.3          7.55                   NaN        None  \n",
       "4                    0.3         55.55                   NaN        None  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet = pd.read_parquet(r\"C:\\Users\\jober\\OneDrive\\Desktop\\Data Science\\Data Science - Study notes\\Data_used\\taxi.parquet\")\n",
    "parquet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interacting with network sources like web APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many websites have public APIs providing dat feeds via JSON (JavaScript Object Notation) format or some other format. There are a number of ways to access these APIs from Python; one easy-to-use and recommended method is the `request` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
