{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Data Science__ \n",
    "\n",
    "## A conceptual framework worth knowing\n",
    "\n",
    "The definition I liked the most is the one offered from AWS, which states that __Data science (DS)__ is the field of study of data to extract meaningful insights from noisy data to provide plausible actions for business. It is a multidisciplinary approach that combines principles and practices from the fields of mathematics, statistics, artificial intelligence, and computer engineering to analyze large amounts of data from a specific domain (area of expertise).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DS Fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science vs Artificial Intelligence vs Machine Learning vs Deep Learning.\n",
    "\n",
    "Artificial Intelligence (AI) is a technique of turning a computer-based robot to work and act like humans. This can be divided into Weak AI, General AI, and Strong AI (indistinguishable from human mind). The latest are hypothetical yet.   \n",
    "\n",
    "Machine Learning (ML) is a branch of Artificial Intelligence (AI) and Computer Science (CS) that focuses on using data and algorithms to imitate how humans learn. This can be divided into Supervised learning which uses labeled data to train models, Unsupervised learning that uses unlabeled datasets to train models, and Reinforced learning where agents learn from feedback - actions and its results -.\n",
    "\n",
    "Deep Learning (DL) is a type of Machine Learning (ML) and Artificial Intelligence (AI) that resembles the way humans gain certain types of knowledge. \n",
    "\n",
    "DS is the domain of study that deals with vast volumes of data using modern tools and techniques (such as AI, ML and DL) to make business decisions. This is a metaskill, which means there is not a single skills set required to succeed in this field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Science Process "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DS Process]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything starts in the real world. As a Data Scientist we focus on a broad analysis of  our phenomena of study, so we come out with a definition of scope and resources needed. \n",
    "\n",
    "- Getting the data (SQL, API, file formats - csv, xlsx, etc. -).\n",
    "\n",
    "This comprises the activities of data acquisition, data entry, signal reception, data extraction from different sources such as statics files, databases, web scraping, APIs and its subsequent storage in a convenient artifact/system.\n",
    "\n",
    "- Data Processing / Data Wrangling (python, pandas)\n",
    "\n",
    "During this stage we rearrange and reshape the data! We manage hierarchical data, handle categorical data, reshape and transform structures, indexing data, or merging/combining/joining data.\n",
    "\n",
    "- Data cleaning (python, pandas)\n",
    "\n",
    "Mostly about identifying missing values and empty data, data imputation, incorrect types, outliers, and performing statistical sanitization. \n",
    "\n",
    "- Analysis. \n",
    "\n",
    "*This is where you typically start in a standard statistics class, with a clean, orderly dataset. But it’s not where you typically start in the real world.* \n",
    "\n",
    "Inferential statistics (pandas, matplotlib / seabon).\n",
    "The Analysis stage can be divided into two parts: Exploration and Modeling. Exploration is about extracting patterns from data! Exploring, Building statistical models, Correlation vs causation analysis, Hypothesis testing, and Statistical Analysis. EDA responds to questions like ¿What’s happening?\n",
    "\n",
    "> In the course of doing EDA, we may realize that it isn’t actually clean because of duplicates, missing values, absurd outliers, and data that wasn’t actually logged or incorrectly logged. If that’s the case, we may have to go back to collect more data, or spend more time cleaning the dataset.\n",
    "\n",
    "\n",
    "Data analysis sometimes goes further than descriptions. In those cases, after exploring our data, we then can proceed to Build ML models, building ETL pipelines, feature engineering, and online deployment to develop some diagnostic and predictive analytics. This is where mainly __Data Scientist__ are called to action.\n",
    "\n",
    "> Diagnostics analytics respond to questions like ¿Why is something happening? Root-cause determination. \n",
    "\n",
    "> Predictive analytics respond to questions like ¿What’s more likely to happen next? \n",
    "    \n",
    "- Visualizations and representation, and reporting (visualization tools)\n",
    "\n",
    "We then can interpret, visualize, report, or communicate our results. This could take the form of reporting the results up to our boss or coworkers, Dashboard preparation, or publishing a paper in a journal and going out and giving academic talks about it. \n",
    "\n",
    "- Action recommendation (Dashboards with dash)\n",
    "\n",
    "The insights gained from the previous analysis, decision making and real-life tests take place. In this stage we suggest the most beneficial course of action.\n",
    "\n",
    "> Prescriptive analytics respond to questions like ¿What do we need to do next? \n",
    "\n",
    "- Building data products.\n",
    "\n",
    "Data science is special and distinct from statistics, so that users interact with data products, and that generates more data, which creates a feedback loop. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data Scientist profile.\n",
    "\n",
    "Data Science can be found in any field. Regardless of their formal educational background, these professionals are well-rounded, data-driven individuals with high-level technical skills who are capable of building complex quantitative algorithms to organize and synthesize large amounts of information used to answer questions and drive strategy in their organization.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Data Analysis__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical statistics focused almost exclusively on _inference_, a sometimes complex set of procedures for drawing conclusions about a large population based on small samples. __Data Analysis__ includes statistical inferences as just one component, linking to engineering and computer science and business domains."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the process for __inspecting, cleansing, tranforming__ and _modeling data_ with the goal of _discovering useful information_, informing conclusion and __supporting decision-making__.\n",
    "\n",
    "inspecting, cleansing, tranforming  => python (pandas) <br>\n",
    "modeling data => inferential statistics (pandas, matplotlib / seabon) <br>\n",
    "discovering useful information => patterns from the data (visualization tools) <br>\n",
    "supponting decision making => dashboards (dash) <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Ecosystem\n",
    "_Pandas:_ For data analysis.\n",
    "_Matplotlib:_ foundational library for visualization. <br>\n",
    "_Numpy:_ The numeric library that serves as the fundation of all calculation in Python. <br>\n",
    "_Seaborn:_ A statistical visualization tool built on top of matplotlib. <br>\n",
    "_Statsmodel:_ A library with many advanced statistical functions. <br>\n",
    "_Scipy:_ Advanced scientific computing, including functions for optimization, linear algebra, image processing and more. <br>\n",
    "_Scikit-Learn:_ The most popular machine learning library for python (not deep learning) <br>\n",
    "\n",
    "Among many other tools for specific use-cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rectangular Data\n",
    "This is the general term for a two dimensional matrix with rows indicating records (cases or observations) and columns indicating features (variables). It is typicaly used in Data Science as a frame of reference for an analysis; _data frame_ is the specific format in R and Python for storing data. However, data doesn't always start in this form: unstructured data (e.g., text) must be processed and manipulated so that it can be represented as a set of features in the rectangular data. Data in data bases must be pulled an put into a single table for most data analysis and modeling tasks.\n",
    "\n",
    "Terminology for rectangular data can be confusing. Statisticians and data scientists use different terms for the same thing. For a statistician, predictor variables are used in a model to predict a response or dependent variable. For a Data scientist, features are used to predict a target. One synonim is particularly confusing: computer scientist will use the term _sample_ for a single row; a _sample_ to a statistician means a collection of rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonrectangular data structures.\n",
    "There are other data structures besides rectangular data. Time series data records successive measurements of the same variable. Its the raw material for the statistical forecasting methods,and it is also a key component of the data produced by devices - The Internet of things.\n",
    "\n",
    "Spatial data structures, which are used in mapping and location analytics, are more complex and varied than rectangular data sutructures. In the object representation, the focus of the data is an object (e.g., a huose) and its spatial coordinates. The field view, by contrast, focuses on small units of space and the value of a relevant metric (pixel brighteness, for example).\n",
    "\n",
    "Graphs (or networks) data structures are used to represent physical, social, and abstract relationships, and are uselful for certain types of problems,such as network optimization and recommender systems. For example, a graph of a social network may represent connections between people on the network. Distribution hubs connected by roads are an example of a physical network. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zoom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b11b869b993da9fb89d9f0f287830444817e260015089d0cac69cf0d7ea70f5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
